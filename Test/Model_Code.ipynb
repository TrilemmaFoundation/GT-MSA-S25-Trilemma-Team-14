{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GT-MSA-S25-Trilemma-Team-14 BTC EDA\n",
    "\n",
    "*Georgia Tech Summer 2025 MSA Practicum Project*  \n",
    "*Model Development*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Executive Summary\n",
    "\n",
    "xxxxxxxx\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explaratory Data Analysis Findings\n",
    "\n",
    " Imagine standing at the heart of a bustling marketplace where every whisper of news, every shift in sentiment, and every strategic move by miners or institutions flows together into a single, living stream—Bitcoin’s price. Unlike isolated on-chain metrics that speak in fragments, price is the universal language of the market: it distills supply and demand, fear and greed, macro shocks and micro opportunities into one immediate reading.\n",
    "\n",
    "When headlines roar about a new ETF approval or regulatory clampdown, when whales quietly accumulate off-exchange, or when miner revenues ebb and surge, all of these forces ripple through price in real time. A sudden plunge signals panic selling or capitulation; a sharp spike reveals frenzy or FOMO. There’s no waiting for lagging indicators or chasing after fractured data feeds—price tells the story as it unfolds.\n",
    "\n",
    "By converting price into log-price Z-scores, we translate that raw narrative into a clear statistical framework. Each dip and peak becomes a chapter marked “overbought” or “oversold,” whether it’s a fleeting 30-day blip or a once-in-four-year cycle event. In this way, price isn’t just great—it is the master storyteller, weaving every voice in the ecosystem into a single, coherent signal that guides smarter accumulation decisions.\n",
    "\n",
    "> Therfore, despite several on-chain and miner metrics, **log-price Z-scores** emerged as the most interpretable, resilient and future-proof signals for building a cycle-aware dynamic DCA strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Demonstrating the Power of Log-Price Z-Scores\n",
    "\n",
    "Below are two key charts both based **solely** on rolling log-price Z-scores—that expose Bitcoin’s multi-year cycle structure and market regimes with crystal-clear precision.\n",
    "\n",
    "#### 2.1.1 4-Year Cycle Phase Heatmap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Extract full-range price series (including pre-2013) if available\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m price_full_all \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPriceUSD\u001b[39m\u001b[38;5;124m\"\u001b[39m] \n\u001b[1;32m     23\u001b[0m log_price_full_all \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(price_full_all)\n\u001b[1;32m     25\u001b[0m windows \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m365\u001b[39m, \u001b[38;5;241m1461\u001b[39m] \n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # Added for np.log\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Helper for centered rolling z-score\n",
    "def rolling_zscore(series: pd.Series, window: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute a trailing rolling z-score of `series` over `window` days,\n",
    "    using min_periods = window // 2. Returns (series - rolling_mean) / rolling_std.\n",
    "    \"\"\"\n",
    "    rolling_mean = series.rolling(window, min_periods=window // 2).mean()\n",
    "    rolling_std  = series.rolling(window, min_periods=window // 2).std()\n",
    "    rolling_std = rolling_std.replace(0, np.nan) \n",
    "    z = (series - rolling_mean) / rolling_std\n",
    "    return z.fillna(0) \n",
    "\n",
    "\n",
    "# Extract full-range price series (including pre-2013) if available\n",
    "price_full_all = df[\"PriceUSD\"] \n",
    "\n",
    "log_price_full_all = np.log(price_full_all)\n",
    "\n",
    "windows = [30, 90, 180, 365, 1461] \n",
    "\n",
    "zscore_full = {}\n",
    "for w in windows:\n",
    "    z = rolling_zscore(log_price_full_all, w).clip(-4, 4)\n",
    "    zscore_full[f\"z_{w}d\"] = z\n",
    "\n",
    "z_df_full_all = pd.DataFrame(zscore_full, index=log_price_full_all.index)\n",
    "\n",
    "\n",
    "# --- Classification function uses your custom thresholds ---\n",
    "phase_labels = {0: 'Deep Accum', 1: 'Neutral', 2: 'Caution', 3: 'Euphoria'}\n",
    "def classify(z):\n",
    "    if z < 0.7:   return 0\n",
    "    if z < 1.0:   return 1\n",
    "    if z < 2.0:   return 2\n",
    "    return 3\n",
    "\n",
    "START, END = \"2011-06-01\", \"2025-05-31\"\n",
    "phase = z_df_full_all['z_1461d'].loc[START:END].map(classify)\n",
    "\n",
    "# Build the pivot table\n",
    "cal = pd.DataFrame({'phase': phase})\n",
    "cal['year']  = cal.index.year\n",
    "cal['month'] = cal.index.month\n",
    "pivot = cal.groupby(['year','month'])['phase'] \\\n",
    "           .first() \\\n",
    "           .unstack(fill_value=np.nan)\n",
    "\n",
    "# Create a discrete colormap and norm for 4 categories\n",
    "cmap = ListedColormap(['#2c7bb6', '#91bfdb', '#fc8d59', '#d7191c'])\n",
    "norm = BoundaryNorm([0,1,2,3,4], ncolors=cmap.N)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "im = ax.imshow(pivot, aspect='auto', origin='lower',\n",
    "               cmap=cmap, norm=norm)\n",
    "\n",
    "# Axis formatting\n",
    "ax.set_yticks(np.arange(len(pivot.index)))\n",
    "ax.set_yticklabels(pivot.index)\n",
    "ax.set_xticks(np.arange(12))\n",
    "ax.set_xticklabels([d.strftime('%b') for d in pd.date_range('2000-01-01', periods=12, freq='M')])\n",
    "ax.set_title('Monthly 4-Year Cycle Phase (1461d Z)', fontsize=14)\n",
    "\n",
    "# Annotate each cell with its phase initial\n",
    "for i in range(pivot.shape[0]):\n",
    "    for j in range(pivot.shape[1]):\n",
    "        code = pivot.iloc[i, j]\n",
    "        if not pd.isna(code):\n",
    "            ax.text(j, i, phase_labels[int(code)][0],\n",
    "                    ha='center', va='center', color='black', fontsize=8)\n",
    "\n",
    "# Colorbar with ticks centered on each category\n",
    "cbar = plt.colorbar(im, ax=ax, ticks=[0.5, 1.5, 2.5, 3.5])\n",
    "cbar.ax.set_yticklabels(['Deep', 'Neutral', 'Caution', 'Euphoria'])\n",
    "cbar.set_label('Cycle Phase', rotation=270, labelpad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1,461-day Z-score was computed on the **first trading day** of each month and bin it into four phases:  \n",
    "- **Deep Dip:** Z < 0.7 (blue) - Months align with extended bear markets (2015, 2018–19, 2022). \n",
    "- **Neutral:** 0.7 ≤ Z < 1.0 (light-blue)  \n",
    "- **Caution:** 1.0 ≤ Z < 2.0 (orange)  \n",
    "- **Euphoria:** Z ≥ 2.0 (red) - Months pinpoint cycle tops (late 2013, late 2017, 2021, late 2024).\n",
    "\n",
    "- Using the first-of-month Z-score ensures each row is anchored to its own cycle baseline, creating a clean, seasonal map of the four-year halving cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Regime Clustering\n",
    "K-Means on the five log-price Z-scores (30d, 90d, 180d, 365d, 1 461d) yields four intuitive regimes—Accumulation, Bull, Bear, Transition that consistently map to major market phases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py:82: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 2.3.1)\n",
      "  import scipy.linalg  # noqa\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'z_df_full_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# --- Prepare features and clustering -------------------------------\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mz_df_full_all\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_30d\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_90d\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_180d\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_365d\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_1461d\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      9\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(features)\n\u001b[1;32m     10\u001b[0m labels_k \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(kmeans\u001b[38;5;241m.\u001b[39mlabels_, index\u001b[38;5;241m=\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z_df_full_all' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Prepare features and clustering -------------------------------\n",
    "features = z_df_full_all[['z_30d','z_90d','z_180d','z_365d','z_1461d']].dropna()\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10).fit(features)\n",
    "labels_k = pd.Series(kmeans.labels_, index=features.index, name='cluster')\n",
    "\n",
    "# Align with price series and restrict to full 2013–2024\n",
    "common_idx = features.index.intersection(price_full_all.index)\n",
    "labels_k = labels_k.loc[common_idx]\n",
    "price_common = price_full_all.loc[common_idx]\n",
    "mask = (price_common.index >= '2011-06-01') & (price_common.index <= '2025-05-31')\n",
    "price_common = price_common.loc[mask]\n",
    "labels_k = labels_k.loc[mask]\n",
    "\n",
    "# --- Plot full period with cluster coloring -------------------------\n",
    "cluster_labels = {\n",
    "    0: 'Volatility / Transition',\n",
    "    1: 'Bear Market',\n",
    "    2: 'Bull Market',\n",
    "    3: 'Consolidation / Accumulation'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "scatter = ax.scatter(\n",
    "    price_common.index,\n",
    "    price_common.values,\n",
    "    c=labels_k.values,\n",
    "    cmap='tab10',\n",
    "    s=20,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "ax.set_title('Z-Score Regime Clusters: 2013–2024', fontsize=16)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('BTC Price (USD)')\n",
    "\n",
    "# Build legend\n",
    "colors = [scatter.cmap(scatter.norm(i)) for i in sorted(cluster_labels.keys())]\n",
    "handles = [\n",
    "    Line2D([0], [0], marker='o', color='w',\n",
    "           markerfacecolor=colors[i], markersize=8,\n",
    "           label=cluster_labels[i])\n",
    "    for i in sorted(cluster_labels.keys())\n",
    "]\n",
    "ax.legend(handles=handles, title='Regime Cluster')\n",
    "\n",
    "# Format x-axis by year\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Accumulation (teal)** appears at cycle lows, marking disciplined buy zones.  \n",
    "- **Bull Market (pink)** tracks explosive up-trends.  \n",
    "- **Bear Market (red)** highlights corrective drawdowns.  \n",
    "- **Transition (blue)** captures periods of heightened volatility and regime shifts.\n",
    "\n",
    "> **Key insight:** These two visualizations built **only** on log-price Z-scores surface every major market regime and cycle phase with unmatched clarity. No additional on-chain, network or valuation metrics were needed to reveal these robust patterns.  \n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Setting the enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import io, pickle, multiprocessing as mp\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Hyperparameters\n",
    "\n",
    "- **`MIN_W = 1 × 10⁻⁵`**  \n",
    "  - Tiny floor under every daily weight → keeps all weights strictly positive and avoids divide-by-zero problems.\n",
    "\n",
    "- **`WINS = [30, 90, 180, 365, 1461]`**  \n",
    "  - Rolling *z*-score look-backs on log-price.  \n",
    "  - Capture momentum / mean-reversion over ≈ 1 month, 1 quarter, ½ year, 1 year and 4 years.\n",
    "\n",
    "- **Back-test span: `2011-06-01` → `2025-06-01`**  \n",
    "  - Long enough to include multiple halving cycles and bear–bull transitions; ends on the latest month data availablity at training time.\n",
    "\n",
    "- **`RHO = 0.90` (exponential-decay factor)**  \n",
    "  - When aggregating per-window scores, newer windows get 10 % more weight than the one just before.\n",
    "\n",
    "- **Regularisation**  \n",
    "  - **`λₐ = λᵦ = 1 × 10⁻³`** on the parameter groups **α** (mixture gates) and **β** (timing modulation).  \n",
    "  - Keeps coefficients modest, reducing over-fit without erasing signal.\n",
    "\n",
    "- **Prototype Beta profiles**  \n",
    "  - **(0.5, 5.0)** front-loads buys.  \n",
    "  - **(1.0, 1.0)** uniform schedule.  \n",
    "  - **(5.0, 0.5)** back-loads buys.  \n",
    "  - A softmax over these three lets the model learn *when* in the year to concentrate capital.\n",
    "\n",
    "- **`np.random.seed(7)`**  \n",
    "  - Fixes the random state so optimisation and results are perfectly reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_W = 1e-5\n",
    "WINS  = [30, 90, 180, 365, 1461]\n",
    "START_BACKTEST = pd.Timestamp(\"2011-06-01\")\n",
    "END_BACKTEST   = pd.Timestamp(\"2025-06-01\")\n",
    "RHO   = 0.90\n",
    "LAMBDA_ALPHA = 1e-3\n",
    "LAMBDA_BETA  = 1e-3\n",
    "PROTOS = [(0.5, 5.0), (1.0, 1.0), (5.0, 0.5)]\n",
    "np.random.seed(7)\n",
    "\n",
    "# Comment out if not using Mac\n",
    "try:\n",
    "    mp.set_start_method(\"fork\", force=True)\n",
    "except RuntimeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Preperation\n",
    "\n",
    "- **`fetch_btc()`**  \n",
    "  - Downloads Coin Metrics’ *raw* BTC CSV (public GitHub mirror).  \n",
    "  - Falls back to the local cache *btc.csv* if the HTTP request fails.  \n",
    "  - Keeps only **`time`** and **`PriceUSD`** columns → lighter payload.  \n",
    "  - Normalises `time` to midnight and sets it as the **DatetimeIndex**.  \n",
    "  - Returns a **`pd.Series`** of dollar price from **2010-07-18** onward (First price available data).\n",
    "\n",
    "\n",
    "- **`price = fetch_btc()`**  \n",
    "  - One-liner that calls the helper and yields the **full history** of daily BTC prices.\n",
    "\n",
    "- **`log_price = np.log(price)`**  \n",
    "  - Natural-log transform → stabilises variance and makes percentage moves additive – crucial for z-score features.\n",
    "\n",
    "- **`price = price_full.loc[START_BACKTEST : END_BACKTEST]`**  \n",
    "  - Trims the series to the official back-test range  \n",
    "    `2011-06-01 → 2025-06-01` (both inclusive).  \n",
    "  - Ensures that every downstream window simulation sees an identical, fixed price vector – no data leakage.\n",
    "\n",
    "*(Note: `price_full` is the untrimmed series; we keep it so that long-horizon rolling statistics—e.g., the 1-year z-score—have enough look-back even for the first back-test window.)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_btc() -> pd.Series:\n",
    "    url, cache = (\"https://raw.githubusercontent.com/coinmetrics/data/\"\n",
    "                  \"master/csv/btc.csv\", Path(\"btc.csv\"))\n",
    "    try:\n",
    "        txt = requests.get(url, timeout=15).text\n",
    "        cache.write_text(txt)\n",
    "    except Exception:\n",
    "        txt = cache.read_text()\n",
    "    df = pd.read_csv(io.StringIO(txt), usecols=[\"time\", \"PriceUSD\"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"time\"]).dt.normalize()\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "    return df[\"PriceUSD\"].loc[\"2010-07-18\":].astype(float)\n",
    "\n",
    "price_full = fetch_btc()\n",
    "log_full   = np.log(price_full)\n",
    "price      = price_full.loc[START_BACKTEST:END_BACKTEST]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Feature-engineering — log-price z-scores  \n",
    "\n",
    "- **`zscore()` helper**  \n",
    "  * Computes a rolling mean and standard deviation over a look-back window `win`.  \n",
    "  * Uses `min_periods = win // 2`, so the very first windows still yield a value instead of NaN.  \n",
    "  * Returns \\((s - m) / $\\text{sd}$): the number of standard deviations today’s log-price is from its recent mean.  \n",
    "  * `fillna(0)` keeps the series numeric before enough history exists.\n",
    "\n",
    "- **`z_all` dataframe**  \n",
    "  * Builds five columns (`z30`, `z90`, `z180`, `z365`, `z1461`) by calling `zscore()` on the full log-price series.  \n",
    "  * `clip(-4, 4)` caps extreme outliers (≈ ±4 σ) so a single shock cannot dominate the softmax / beta mix later on.\n",
    "\n",
    "- **`z_lag = z_all.shift(1).fillna(0)`**  \n",
    "  * Shifts every z-score back by one day, forcing the model to use only yesterday’s information — eliminating look-ahead bias.  \n",
    "  * Any NaNs introduced by the shift are filled with zero for clean downstream vector maths.\n",
    "\n",
    "- **`FEATS` list**  \n",
    "  * A simple list of the five feature names; makes later matrix operations more readable.\n",
    "\n",
    "**Why log-price?**  Log returns are additive and closer to normal; z-scores on the log scale therefore have a stable interpretation across Bitcoin’s six-order-of-magnitude price history.\n",
    "\n",
    "**Why `min_periods = win // 2`?**  It is a compromise: we want signals as early as possible, but we also need enough data points to avoid wildly unstable estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(s: pd.Series, win: int) -> pd.Series:\n",
    "    m  = s.rolling(win, win // 2).mean()\n",
    "    sd = s.rolling(win, win // 2).std()\n",
    "    return ((s - m) / sd).fillna(0)\n",
    "\n",
    "z_all = pd.DataFrame({f\"z{w}\": zscore(log_full, w).clip(-4, 4) for w in WINS})\n",
    "z_lag = z_all.shift(1).fillna(0)\n",
    "FEATS = z_lag.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Rolling–window index & uniform-DCA baseline  \n",
    "\n",
    "- **`WINDOW_STARTS`**  \n",
    "  * Generates a *daily* sequence of start-dates from **2011-06-01** through **2024-06-02**.  \n",
    "  * We stop at `END_BACKTEST – 364 days` so that **every start-date has a full 365-day window** available.  \n",
    "  * Result: `WINDOW_N = 4 751` consecutive 12-month windows.\n",
    "\n",
    "- **Uniform DCA benchmark (`uniform_spd_pct`)**  \n",
    "  * For any index of 365 dates:  \n",
    "    1. Buy the *same fiat amount every day* ⇒ equal weights `1/365`.  \n",
    "    2. Compute *sats per dollar* (SPD) harvested by that schedule.  \n",
    "    3. Express it as a **percentile** between the best-possible timing (buy only on the single cheapest day in the window) and the worst-possible timing (buy only on the single most expensive day).  \n",
    "  * Output is therefore a 0–100 score: 50 ≈ median timing, 100 = perfect timing.\n",
    "\n",
    "- **`UNIFORM_PCT`**  \n",
    "  * Pre-computes the above percentile **for every daily window in `WINDOW_STARTS`**.  \n",
    "  * Shape = `(4 750,)`; used as the yard-stick to decide whether our dynamic strategy “wins” on a given window (`dynamic_pct > UNIFORM_PCT`).\n",
    "\n",
    "- **`MONTHLY_MASK`**  \n",
    "  * Boolean vector (length 4 750) that is **`True` only for windows whose start-date is the 1st of the month** (`freq=\"MS\"`).  \n",
    "  * Those ~160 windows are treated as the *training* set during optimisation; the remaining ~4 600 daily windows form the *evaluation* set.  \n",
    "  * This gives a huge out-of-sample test while still letting the optimiser “see” representative periods spread across the full back-test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_STARTS = pd.date_range(\n",
    "    START_BACKTEST,\n",
    "    END_BACKTEST - pd.Timedelta(364, \"D\"),\n",
    "    freq=\"D\"\n",
    ")\n",
    "WINDOW_N = len(WINDOW_STARTS)\n",
    "\n",
    "def uniform_spd_pct(idx: pd.DatetimeIndex) -> float:\n",
    "    w  = np.full(len(idx), 1 / len(idx))\n",
    "    btc = (w / price.loc[idx].values).sum()\n",
    "    worst, best = 1 / price.loc[idx].max(), 1 / price.loc[idx].min()\n",
    "    return 100 * (btc - worst) / (best - worst)\n",
    "\n",
    "UNIFORM_PCT = np.array([\n",
    "    uniform_spd_pct(price.loc[s : s + pd.Timedelta(364, \"D\")].index)\n",
    "    for s in WINDOW_STARTS\n",
    "])\n",
    "\n",
    "MONTHLY_MASK = np.isin(\n",
    "    WINDOW_STARTS,\n",
    "    pd.date_range(START_BACKTEST,\n",
    "                  END_BACKTEST - pd.Timedelta(364, \"D\"),\n",
    "                  freq=\"MS\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Core optimisation helpers & objective\n",
    "\n",
    "* **`softmax(x)`**  \n",
    "  Converts a 6-D logit vector into a 3-element probability simplex  \n",
    "  $$\n",
    "    \\text{softmax}(x)_i =\n",
    "    \\frac{\\exp\\!\\left(x_i - \\max(x)\\right)}\n",
    "         {\\sum_j \\exp\\!\\left(x_j - \\max(x)\\right)}\n",
    "  $$\n",
    "  Subtracting $\\max(x)$ avoids overflow in the exponentials.\n",
    "\n",
    "* **`allocate_sequential(raw)`**  \n",
    "  Maps un-normalised scores `raw` to final weights `w` that  \n",
    "  1. respect the floor `MIN_W`,  \n",
    "  2. preserve rank order,  \n",
    "  3. sum exactly to 1.  \n",
    "  It steps left→right, distributing the remaining budget\n",
    "  in proportion to each day’s remaining raw score.\n",
    "\n",
    "* **`beta_mix_pdf`$(n,\\;\\text{mix})$**\n",
    "\n",
    "  Builds a smooth 365-point timing profile  \n",
    "  $$\n",
    "    f(t)=\\sum_{k=1}^{3}\\text{mix}_k\\,\n",
    "          \\text{BetaPDF}\\!\\bigl(t;\\,a_k,b_k\\bigr),\\qquad\n",
    "          t\\in\\!\\bigl(\\tfrac{1}{2n},\\,1-\\tfrac{1}{2n}\\bigr)\n",
    "  $$\n",
    "  with shapes $(a_k,b_k)\\in\\texttt{PROTOS}$, normalised so\n",
    "  $\\sum_d f_d = 1$.\n",
    "\n",
    "\n",
    "* **`simulate_window(start, θ)`** – SPD percentile for a single 12-month slice  \n",
    "\n",
    "  1. **Parameter split**: θ → **α** (3 × 6 logits) and **β** (5 loadings).  \n",
    "  2. **Mixture weights**: `mix = softmax(α @ [1, z₁ … z₅])`.  \n",
    "  3. **Base timing curve**: `beta_mix_pdf(365, mix)`.  \n",
    "  4. **Feature modulation**: $\\exp\\!\\bigl(-\\,Z_d\\cdot\\beta\\bigr)$ for each day *d*.  \n",
    "  5. **Combine & normalise**: (base × modulation) → `allocate_sequential` → final weights **w**.  \n",
    "  6. **Value metric**:  \n",
    "     $$\n",
    "       \\text{SPD} \\;=\\; \\sum_d \\frac{w_d}{\\text{Price}_d},\n",
    "       \\qquad\n",
    "       \\text{Percentile} \\;=\\;  \\,\\frac{\\text{SPD}-\\text{worst}}{\\text{best}-\\text{worst}} \\times 100 \n",
    "     $$\n",
    "\n",
    "\n",
    "* **`metric(θ, mask)`** – optimiser objective  \n",
    "\n",
    "  * `spd` = array of SPD-percentiles for all windows selected by `mask`.  \n",
    "  * `win` = percentage of those windows where `spd` beats the uniform-DCA percentile.  \n",
    "  * `rw`  = exponentially-decayed mean of `spd` with ρ = 0.9 (newer windows get more weight).  \n",
    "  * **Return:** `(rw, win, 0.5 × rw + 0.5 × win)` — exactly the competition’s leaderboard score.\n",
    "\n",
    "\n",
    "These helpers give the optimiser a **differentiable, single-pass evaluation**\n",
    "of any parameter vector $\\theta$, while the allocation floor `MIN_W`\n",
    "keeps every window numerically stable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x): ex = np.exp(x - x.max()); return ex / ex.sum()\n",
    "\n",
    "def allocate_sequential(raw):\n",
    "    n = len(raw); floor = n * MIN_W\n",
    "    rem_budget, rem_raw = 1 - floor, raw.sum()\n",
    "    w = np.empty_like(raw)\n",
    "    for i, x in enumerate(raw):\n",
    "        share = 0 if rem_raw == 0 else (x / rem_raw) * rem_budget\n",
    "        w[i]  = MIN_W + share\n",
    "        rem_budget -= share; rem_raw -= x\n",
    "    return w / w.sum()\n",
    "\n",
    "def beta_mix_pdf(n, mix):\n",
    "    t = np.linspace(0.5 / n, 1 - 0.5 / n, n)\n",
    "    return (mix[0] * beta.pdf(t, *PROTOS[0]) +\n",
    "            mix[1] * beta.pdf(t, *PROTOS[1]) +\n",
    "            mix[2] * beta.pdf(t, *PROTOS[2])) / n\n",
    "\n",
    "def simulate_window(start, theta):\n",
    "    idx = price.loc[start : start + pd.Timedelta(364, \"D\")].index\n",
    "    if len(idx) < 365:\n",
    "        return np.nan\n",
    "    alpha, beta_v = theta[:18].reshape(3, 6), theta[18:]\n",
    "    mix  = softmax(alpha @ np.r_[1, z_lag.loc[idx[0], FEATS].values])\n",
    "    raw  = beta_mix_pdf(365, mix) * np.exp(-(z_lag.loc[idx, FEATS].values @ beta_v))\n",
    "    wts  = allocate_sequential(raw)\n",
    "    btc  = (wts / price.loc[idx].values).sum()\n",
    "    worst, best = 1 / price.loc[idx].max(), 1 / price.loc[idx].min()\n",
    "    return 100 * (btc - worst) / (best - worst + 1e-12)\n",
    "\n",
    "def metric(theta, mask):\n",
    "    spd = np.array([simulate_window(s, theta) for s in WINDOW_STARTS[mask]])\n",
    "    win = 100 * np.mean(spd > UNIFORM_PCT[mask])\n",
    "    weights = RHO ** np.arange(mask.sum())[::-1]\n",
    "    rw = np.nansum(weights * spd) / weights.sum()\n",
    "    return rw, win, 0.5 * rw + 0.5 * win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Optimiser set-up\n",
    "\n",
    "* **Search space – `BOUNDS`**  \n",
    "  * first 18 coords (α-block): each ∈ **[-3, +3]** –– unrestricted logits  \n",
    "  * last  5 coords (β-block): each ∈ **[0, 5]**  –– non-negative feature weights  \n",
    "\n",
    "* **`de_obj(θ, mask)`** – objective supplied to *SciPy*’s `differential_evolution`  \n",
    "  1. Evaluate the rolling-window **reward** and **win-rate**:  \n",
    "     `(rw, win, _) = metric(θ, mask)`.  \n",
    "  2. Add an ℓ² regularisation term  \n",
    "     $$\\lambda_\\alpha \\|θ_{1:18}\\|_2^{\\,2}\\;+\\;\\lambda_\\beta \\|θ_{19:23}\\|_2^{\\,2}$$  \n",
    "     to discourage extreme values.  \n",
    "  3. Return the **negative** of the scoring function  \n",
    "     $$-\\Bigl(\\tfrac12\\,\\text{rw} + \\tfrac12\\,\\text{win} - \\text{penalty}\\Bigr)$$  \n",
    "     because DE is a *minimiser*.\n",
    "\n",
    "* **`fit(mask, seed=0)`** – convenience wrapper  \n",
    "  * Runs **differential evolution** with  \n",
    "    `workers=-1` (all CPU cores) and `updating=\"deferred\"` (faster thread-safe queue).  \n",
    "  * Loose stop-conditions: `maxiter=1 000 000`, `tol=1 e-6`, then `polish=True` for a final L-BFGS step.  \n",
    "  * Returns the best parameter vector **θ** found for the selected windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUNDS = [(-3, 3)] * 18 + [(0, 5)] * 5\n",
    "def de_obj(theta, mask):\n",
    "    rw, win, _ = metric(theta, mask)\n",
    "    pen = (LAMBDA_ALPHA * np.linalg.norm(theta[:18]) ** 2 +\n",
    "           LAMBDA_BETA  * np.linalg.norm(theta[18:]) ** 2)\n",
    "    return -(0.5 * rw + 0.5 * win - pen)\n",
    "\n",
    "def fit(mask, seed=0):\n",
    "    return differential_evolution(\n",
    "        de_obj, BOUNDS, args=(mask,),\n",
    "        seed=seed, workers=-1, updating=\"deferred\",\n",
    "        maxiter=1_000_000, tol=1e-6, polish=True\n",
    "    ).x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8  Single hold-out cross-validation\n",
    "\n",
    "* **Chronological split**  \n",
    "  * **Cut-off date:** **1 Jan 2021** (`cutoff = Timestamp(\"2021-01-01\")`).  \n",
    "  * `train` mask = all **monthly** starts **\\< cutoff**  \n",
    "    (roughly one window per month – quick yet representative).  \n",
    "  * `test` mask = **every daily** start **≥ cutoff**  \n",
    "    (a very large, truly out-of-sample evaluation set).\n",
    "\n",
    "* **Procedure**  \n",
    "  1. Print the number of windows in each split.  \n",
    "  2. **Fit** parameters on the training subset:  \n",
    "     `θ = fit(train, seed)`.  \n",
    "  3. **Evaluate** on the unseen test windows:  \n",
    "     `(rw, win, score) = metric(θ, test)`.  \n",
    "  4. **Report** – emits a single summary line of the form  \n",
    "     ```\n",
    "     RW <value> | Win <value> | Score <value>\n",
    "     ```  \n",
    "     showing the rolling-window percentile (`RW`), win rate (`Win`), and the\n",
    "     blended competition score.\n",
    "\n",
    "* **Reproducibility** — the optional `seed` argument flows into the\n",
    "  differential-evolution optimiser, ensuring deterministic results.\n",
    "\n",
    "* **Return value**  \n",
    "  `(θ, rw, win, score)` — enables inspection of the fitted parameters and\n",
    "  their hold-out performance before running the final full-data optimisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_cv(seed=17):\n",
    "    cutoff = pd.Timestamp(\"2021-01-01\")\n",
    "    train  = (WINDOW_STARTS < cutoff) & MONTHLY_MASK\n",
    "    test   =  WINDOW_STARTS >= cutoff\n",
    "    print(f\"[CV] Train windows (monthly) : {train.sum()}\")\n",
    "    print(f\"[CV] Test  windows  (daily)  : {test.sum()}\\n\")\n",
    "    theta = fit(train, seed)\n",
    "    rw, win, sc = metric(theta, test)\n",
    "    print(f\"[CV] RW {rw:6.2f} | Win {win:5.1f} | Score {sc:6.2f}\\n\")\n",
    "    return theta, rw, win, sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9  Final model fit\n",
    "\n",
    "* **Training data**  \n",
    "  * Uses the full set of **all monthly start-dates** (`MONTHLY_MASK`) across\n",
    "    the entire back-test period.  \n",
    "  * Guarantees the optimiser sees each market regime at least once while\n",
    "    keeping the problem size manageable.\n",
    "\n",
    "* **Optimisation**  \n",
    "  ```python\n",
    "  θ = fit(MONTHLY_MASK, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fit(seed=42):\n",
    "    theta = fit(MONTHLY_MASK, seed)\n",
    "    rw, win, sc = metric(theta, np.ones(WINDOW_N, bool))\n",
    "    return theta, rw, win, sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Model Run\n",
    "\n",
    "* **Metadata banner** – quickly confirms the experiment’s scale  \n",
    "  (`WINDOW_N` daily windows, `MONTHLY_MASK.sum()` monthly ones).\n",
    "\n",
    "* **Hold-out CV run** – sanity-checks generalisation before committing to the\n",
    "  expensive full fit.\n",
    "\n",
    "* **Final training** – re-fits on **all** monthly windows for the strongest\n",
    "  in-sample model and prints the same three headline metrics.\n",
    "\n",
    "* **Parameter inspection** – dumps the 23 learned values so they can be logged\n",
    "  in version control or copied into production code.\n",
    "\n",
    "* **Pickle artefact** – serialises both the parameters and their headline\n",
    "  stats for reproducibility (exact values, seed, and score captured in a\n",
    "  single file).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\"[INFO] daily windows evaluated : {WINDOW_N}\")\n",
    "    print(f\"[INFO] monthly windows         : {MONTHLY_MASK.sum()}\\n\")\n",
    "\n",
    "    # single hold-out CV\n",
    "    holdout_cv()\n",
    "\n",
    "    # final model\n",
    "    print(\"[FULL] fit on ALL monthly windows …\")\n",
    "    θ, rw_f, win_f, sc_f = final_fit()\n",
    "    print(f\"[FULL] RW {rw_f:6.2f} | Win {win_f:5.1f} | Score {sc_f:6.2f}\\n\")\n",
    "    print(\"[PARAM] θ (23 values):\")\n",
    "    print(np.round(θ, 4).tolist())\n",
    "\n",
    "    with open(\"dynamic_dca_theta.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\"theta\": θ,\n",
    "                     \"rw_spd_pct\": rw_f,\n",
    "                     \"win_rate\": win_f,\n",
    "                     \"score\": sc_f}, f)\n",
    "    print(\"\\n[SAVE] → dynamic_dca_theta_monthly.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation results  \n",
    "* **Reward-weighted percentile:** ≈ 83  \n",
    "* **Win-rate vs. uniform DCA:** 100 %  \n",
    "* **Composite score:** ≈ 91  \n",
    "\n",
    "> Holding out every daily window **from 2021-01-01 onward**, the strategy beats\n",
    "> uniform DCA **in all 1 249 test windows** while maintaining a high average\n",
    "> percentile, confirming strong generalisation.\n",
    "\n",
    "---\n",
    "\n",
    "### Full back-test results  \n",
    "* **Reward-weighted percentile:** ≈ 89.6  \n",
    "* **Win-rate vs. uniform DCA:** ≈ 99.4 %  \n",
    "* **Composite score:** ≈ 94.5  \n",
    "\n",
    "> After refitting on **all 157 monthly start-dates** the model lifts its\n",
    "> average percentile and keeps an almost-perfect win-rate, delivering the\n",
    "> highest overall score observed.\n",
    "\n",
    "---\n",
    "\n",
    "### Key observations  \n",
    "* **Stability** – Two independent optimisation runs converge to virtually the\n",
    "  same metrics, showing the search landscape is well-conditioned.  \n",
    "* **Dominance** – The strategy outperforms uniform DCA in **> 99 %** of all\n",
    "  4 751 rolling windows, spanning bull, bear, and sideways markets.  \n",
    "* **Headroom** – The modest gap between cross-val and full-fit scores\n",
    "  (≈ 3½ points) suggests the model extracts additional signal from the extra\n",
    "  data without overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = [1.3507, 1.073, -1.226, 2.5141, 2.9946, -0.4083,\n",
    "         -0.1082, -0.6809, 0.3465, -0.6804, -2.9974, -2.9991,\n",
    "         -1.2658, -0.368, 0.7567, -1.9627, -1.9124, 2.9983,\n",
    "         0.5704, 0.0, 0.8669, 1.2546, 5.0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <button onclick=\"var img=document.getElementById('btcGif'); img.src = img.src;\"\n",
       "            style=\"margin-bottom:6px; padding:4px 10px; font-weight:bold;\">\n",
       "        ↺ Replay\n",
       "    </button><br>\n",
       "    <img id=\"btcGif\" src=\"btc_monthly_windows.gif\"\n",
       "         style=\"max-width:100%; border:1px solid #ddd; border-radius:4px;\">\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ─── 9 ▸ Monthly-window “why it invests” GIF  (equal panels, orange stems) ──\n",
    "#\n",
    "# • Upper panel  : log-price\n",
    "# • Lower panel  : baseline curve + orange lollipop weights\n",
    "# • Output       : btc_monthly_windows.gif     (0.3 fps  ≃ 3.3 s / frame)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np, matplotlib.pyplot as plt, matplotlib.ticker as mtick\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import beta\n",
    "import imageio.v2 as imageio\n",
    "from IPython.display import HTML, display\n",
    "from io import BytesIO\n",
    "\n",
    "θ = np.asarray(theta, dtype=float)\n",
    "α = θ[:18].reshape(3, 6)\n",
    "β = θ[18:]\n",
    "\n",
    "def beta_curve(n=365, mix=(1/3, 1/3, 1/3)):\n",
    "    x = np.linspace(0.5/n, 1-0.5/n, n)\n",
    "    y = (mix[0] * beta.pdf(x, *PROTOS[0]) +\n",
    "         mix[1] * beta.pdf(x, *PROTOS[1]) +\n",
    "         mix[2] * beta.pdf(x, *PROTOS[2]))\n",
    "    return y / y.sum()\n",
    "\n",
    "frames         = []\n",
    "WINDOW_MONTHLY = WINDOW_STARTS[MONTHLY_MASK]\n",
    "\n",
    "for start in WINDOW_MONTHLY:\n",
    "    end = start + pd.Timedelta(364, \"D\")\n",
    "    idx = price_full.loc[start:end].index\n",
    "    if len(idx) < 365:\n",
    "        continue\n",
    "\n",
    "    z0   = z_lag.loc[start, FEATS].values\n",
    "    mix  = softmax(α @ np.r_[1, z0])\n",
    "    base = beta_curve(365, mix)\n",
    "    mod  = np.exp(-(z_lag.loc[idx, FEATS].values @ β))\n",
    "    raw  = base * mod\n",
    "    w    = allocate_sequential(raw)\n",
    "\n",
    "    # ── figure: slightly smaller, equal panels ───────────────────────────\n",
    "    fig, (ax_price, ax_alloc) = plt.subplots(\n",
    "        2, 1, figsize=(9, 5), dpi=160,\n",
    "        gridspec_kw={'height_ratios': [1, 1]},\n",
    "        constrained_layout=True\n",
    "    )\n",
    "    fig.suptitle(\n",
    "        f\"Window starting {start.date()}   •   baseline mix = {mix.round(2)}\",\n",
    "        fontsize=11, weight='bold'\n",
    "    )\n",
    "\n",
    "    # upper – BTC price\n",
    "    ax_price.plot(idx, price_full.loc[idx], lw=1.4, color='black')\n",
    "    ax_price.set_ylabel(\"BTC price  [USD]\\n(log-scale)\")\n",
    "    ax_price.set_yscale('log')\n",
    "    ax_price.xaxis.set_major_locator(mtick.MaxNLocator(5))\n",
    "    ax_price.grid(alpha=0.25)\n",
    "\n",
    "    # lower – baseline + orange lollipops\n",
    "    ax_alloc.plot(idx, base, lw=1.2, color='lightgray', label='baseline')\n",
    "    ax_alloc.vlines(idx, base, w, color='orange', lw=2.2)\n",
    "    ax_alloc.scatter(idx, w, color='orange', s=22, zorder=3, label='weight')\n",
    "    ax_alloc.set_ylabel(\"weight  (log-scale)\")\n",
    "    ax_alloc.set_yscale('log')\n",
    "    ax_alloc.set_ylim(MIN_W*0.8, max(w.max(), base.max())*1.4)\n",
    "    ax_alloc.xaxis.set_major_locator(mtick.MaxNLocator(5))\n",
    "    ax_alloc.grid(alpha=0.25)\n",
    "    ax_alloc.legend(handles=[Line2D([], [], color='orange', lw=2.2,\n",
    "                                    label='final weight')])\n",
    "\n",
    "    # save this frame\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format='png', facecolor='white')\n",
    "    buf.seek(0)\n",
    "    frames.append(imageio.imread(buf))\n",
    "    buf.close()\n",
    "    plt.close(fig)\n",
    "\n",
    "# ── write slow GIF & replay button ───────────────────────────────────────\n",
    "if frames:\n",
    "    imageio.mimsave(\"btc_monthly_windows.gif\", frames, fps=0.3)  # ≃3.3 s / frame\n",
    "    html = \"\"\"\n",
    "    <button onclick=\"var img=document.getElementById('btcGif'); img.src = img.src;\"\n",
    "            style=\"margin-bottom:6px; padding:4px 10px; font-weight:bold;\">\n",
    "        ↺ Replay\n",
    "    </button><br>\n",
    "    <img id=\"btcGif\" src=\"btc_monthly_windows.gif\"\n",
    "         style=\"max-width:100%; border:1px solid #ddd; border-radius:4px;\">\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "else:\n",
    "    print(\"No frames generated – check data range.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c6bee\">\n",
       "  <caption>α – mixture logits</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c6bee_level0_col0\" class=\"col_heading level0 col0\" >Intercept</th>\n",
       "      <th id=\"T_c6bee_level0_col1\" class=\"col_heading level0 col1\" >z30</th>\n",
       "      <th id=\"T_c6bee_level0_col2\" class=\"col_heading level0 col2\" >z90</th>\n",
       "      <th id=\"T_c6bee_level0_col3\" class=\"col_heading level0 col3\" >z180</th>\n",
       "      <th id=\"T_c6bee_level0_col4\" class=\"col_heading level0 col4\" >z365</th>\n",
       "      <th id=\"T_c6bee_level0_col5\" class=\"col_heading level0 col5\" >z1461</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c6bee_level0_row0\" class=\"row_heading level0 row0\" >Early-bias</th>\n",
       "      <td id=\"T_c6bee_row0_col0\" class=\"data row0 col0\" >+1.351</td>\n",
       "      <td id=\"T_c6bee_row0_col1\" class=\"data row0 col1\" >+1.073</td>\n",
       "      <td id=\"T_c6bee_row0_col2\" class=\"data row0 col2\" >-1.226</td>\n",
       "      <td id=\"T_c6bee_row0_col3\" class=\"data row0 col3\" >+2.514</td>\n",
       "      <td id=\"T_c6bee_row0_col4\" class=\"data row0 col4\" >+2.995</td>\n",
       "      <td id=\"T_c6bee_row0_col5\" class=\"data row0 col5\" >-0.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6bee_level0_row1\" class=\"row_heading level0 row1\" >Uniform-bias</th>\n",
       "      <td id=\"T_c6bee_row1_col0\" class=\"data row1 col0\" >-0.108</td>\n",
       "      <td id=\"T_c6bee_row1_col1\" class=\"data row1 col1\" >-0.681</td>\n",
       "      <td id=\"T_c6bee_row1_col2\" class=\"data row1 col2\" >+0.346</td>\n",
       "      <td id=\"T_c6bee_row1_col3\" class=\"data row1 col3\" >-0.680</td>\n",
       "      <td id=\"T_c6bee_row1_col4\" class=\"data row1 col4\" >-2.997</td>\n",
       "      <td id=\"T_c6bee_row1_col5\" class=\"data row1 col5\" >-2.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6bee_level0_row2\" class=\"row_heading level0 row2\" >Late-bias</th>\n",
       "      <td id=\"T_c6bee_row2_col0\" class=\"data row2 col0\" >-1.266</td>\n",
       "      <td id=\"T_c6bee_row2_col1\" class=\"data row2 col1\" >-0.368</td>\n",
       "      <td id=\"T_c6bee_row2_col2\" class=\"data row2 col2\" >+0.757</td>\n",
       "      <td id=\"T_c6bee_row2_col3\" class=\"data row2 col3\" >-1.963</td>\n",
       "      <td id=\"T_c6bee_row2_col4\" class=\"data row2 col4\" >-1.912</td>\n",
       "      <td id=\"T_c6bee_row2_col5\" class=\"data row2 col5\" >+2.998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1507ef9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = np.array(theta[:18]).reshape(3, 6)\n",
    "\n",
    "alpha_df = pd.DataFrame(alpha,\n",
    "                        index=[\"Early-bias\", \"Uniform-bias\", \"Late-bias\"],\n",
    "                        columns=[\"Intercept\", \"z30\", \"z90\", \"z180\", \"z365\", \"z1461\"])\n",
    "beta_s  = pd.Series(beta_v, index=[\"z30\", \"z90\", \"z180\", \"z365\", \"z1461\"])\n",
    "\n",
    "display(alpha_df.style.format(\"{:+.3f}\").set_caption(\"α – mixture logits\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the **α mixture logits**\n",
    "\n",
    "Below are the three Beta-mixture “personas” the optimiser discovered.  \n",
    "Remember: logits are transformed with a *softmax*, so higher ⇒ higher mixture weight.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1 · Early-bias curve  _(front-loads buying)_\n",
    "\n",
    "* **Baseline weight:** logit ≈ +1.35 → ~60 % of the mixture when all z-scores are zero.  \n",
    "* **Signals that **increase** this component**  \n",
    "  * `z365` (+2.99) & `z180` (+2.51): strong upward momentum over 6–12 months.  \n",
    "  * `z30` (+1.07): short-term follow-through.  \n",
    "* **Signals that **decrease** it**  \n",
    "  * `z90` (–1.23): mild 3-month strength tempers aggression.  \n",
    "  * `z1461` (–0.41): if price is only modestly above its 4-year mean.  \n",
    "* **Story:** When Bitcoin is trending up on multi-month horizons, the strategy wants to “get in early” and accelerates purchases near the start of the 12-month window.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2 · Uniform-bias curve  _(evenly spreads buying)_\n",
    "\n",
    "* **Baseline weight:** logit ≈ –0.11 → ~22 % by default.  \n",
    "* **Signals nudging it **up**  \n",
    "  * `z90` (+0.35): momentum is neither hot nor cold → stay neutral.  \n",
    "* **Signals nudging it **down**  \n",
    "  * Very negative logits on `z365` (–3.00) & `z1461` (–3.00) suppress this curve when the market is extended.  \n",
    "* **Story:** Acts as a “neutral buffer”. It dominates only when momentum is middling and there’s no strong valuation signal.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3 · Late-bias curve  _(back-loads buying)_\n",
    "\n",
    "* **Baseline weight:** logit ≈ –1.27 → ~15 % default share.  \n",
    "* **Signals that **increase** this component**  \n",
    "  * `z1461` (+3.00): price sits far **above** its 4-year moving average ⇒ wait for dips.  \n",
    "  * `z90` (+0.76): short-term firmness within an over-extended market.  \n",
    "* **Signals that **decrease** it**  \n",
    "  * `z180` (–1.96) & `z365` (–1.91): strong medium-term momentum argues against delaying too much.  \n",
    "* **Story:** Kicks in after big, prolonged rallies. By shifting weight toward the end of the window, it avoids chasing highs and averages into potential pullbacks.\n",
    "\n",
    "---\n",
    "\n",
    "#### Quick takeaway\n",
    "\n",
    "* **Momentum-driven acceleration:** multi-month strength flips the timing curve to “buy sooner”.  \n",
    "* **Valuation-driven caution:** extreme over-valuation relative to the 4-year trend delays purchases.  \n",
    "* The always-present **uniform** component prevents the schedule from becoming too extreme in either direction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_85da9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_85da9_level0_col0\" class=\"col_heading level0 col0\" >β – daily penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_85da9_level0_row0\" class=\"row_heading level0 row0\" >z30</th>\n",
       "      <td id=\"T_85da9_row0_col0\" class=\"data row0 col0\" >+0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_85da9_level0_row1\" class=\"row_heading level0 row1\" >z90</th>\n",
       "      <td id=\"T_85da9_row1_col0\" class=\"data row1 col0\" >+0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_85da9_level0_row2\" class=\"row_heading level0 row2\" >z180</th>\n",
       "      <td id=\"T_85da9_row2_col0\" class=\"data row2 col0\" >+0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_85da9_level0_row3\" class=\"row_heading level0 row3\" >z365</th>\n",
       "      <td id=\"T_85da9_row3_col0\" class=\"data row3 col0\" >+1.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_85da9_level0_row4\" class=\"row_heading level0 row4\" >z1461</th>\n",
       "      <td id=\"T_85da9_row4_col0\" class=\"data row4 col0\" >+5.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1504be950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_v = np.array(theta[18:])\n",
    "\n",
    "beta_s  = pd.Series(beta_v, index=[\"z30\", \"z90\", \"z180\", \"z365\", \"z1461\"])\n",
    "\n",
    "display(beta_s.to_frame(\"β – daily penalty\").style.format(\"{:+.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3. Helper: build a 365-day timing curve for any feature vector z\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "PROTOS = [(0.5, 5.0), (1.0, 1.0), (5.0, 0.5)]       # early, uniformish, late\n",
    "\n",
    "def softmax(x):\n",
    "    ex = np.exp(x - x.max())\n",
    "    return ex / ex.sum()\n",
    "\n",
    "def beta_mix_pdf(n, mix):\n",
    "    t = np.linspace(0.5 / n, 1 - 0.5 / n, n)\n",
    "    curve = sum(m * beta.pdf(t, *pb) for m, pb in zip(mix, PROTOS))\n",
    "    return curve / curve.sum()\n",
    "\n",
    "def timing_curve(z):                                # z = np.array(5)\n",
    "    mix  = softmax(alpha @ np.r_[1.0, z])           # ← add intercept\n",
    "    base = beta_mix_pdf(365, mix)\n",
    "    mod  = np.exp(-(z @ beta_v))                    # same factor for all days\n",
    "    w    = base * mod\n",
    "    return w / w.sum()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4. Three illustrative scenarios\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "scenarios = {\n",
    "    \"Bearish (all z < −2)\": np.full(5, -2.0),\n",
    "    \"Neutral  (all z 0)\":   np.zeros(5),\n",
    "    \"Bullish (all z > +2)\": np.full(5,  2.0),\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for name, z in scenarios.items():\n",
    "    ax.plot(timing_curve(z), label=name)\n",
    "ax.set(title=\"365-day timing curves for three market regimes\",\n",
    "       xlabel=\"Day in window (0 = first)\", ylabel=\"Weight\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
